{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c581aaed",
   "metadata": {},
   "source": [
    "# DTSC-670 Final Project\n",
    "## Part 1: Technical Implementation\n",
    "\n",
    "### Name: Chukwuemeka Ibebuike"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3643221b",
   "metadata": {},
   "source": [
    "## Academic Integrity\n",
    "\n",
    "**Key Principle: All work must be your own**\n",
    "\n",
    "Plagiarism checks will be conducted at the end of the term for both code and written documents.\n",
    "\n",
    "While you may look online for inspiration, all work in your project must be your own. Do not copy ideas from online sources or collaborate with classmates. Do not use Large Language Models (LLMs) to write your code. Relying on LLMs undermines your learning experience and violates academic ethics. This course is designed to develop your skills.\n",
    "\n",
    "Do not share or post your work online. Use private repositories if needed. \n",
    "\n",
    "Violations will result in a zero grade for the assignment, possible failure of the course, and potential dismissal from the program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c17f6e4",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "### Machine Learning Task\n",
    "Suppose you work in the Advising Team for a large Portuguese school system, and your school director has asked you to analyze student data and create a machine learning model to predict a student’s performance based on select features. Your director hopes to use this information to identify students who might need additional assistance and interventions to improve their grades.\n",
    "\n",
    "Your task is to create a regression model to predict a student's grade. You will need to clean and prepare the data to ensure it is suitable for analysis. After building the model, you will evaluate its performance using appropriate metrics to assess its accuracy and effectiveness.\n",
    "\n",
    "### Note\n",
    "Follow the instructions carefully and submit your notebook to CodeGrade for testing. Ensure you name the variables as indicated, as CodeGrade requires specific naming for proper evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ba3422",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "\n",
    "Begin by importing and inspecting your dataset to ensure it is correctly loaded and understand its structure. This initial step sets the foundation for your analysis and modeling.\n",
    "\n",
    "1) **Import the Data**: Correctly import your data.\n",
    "2) **Initial Data Check**: Check the initial data, including size and data types.\n",
    "3) **Identify the Target**: Identify the target attribute.\n",
    "4) **Split the Data**: Split your data into training and test sets using the variable names `X_train`, `X_test`, `y_train`, and `y_test`.  Use `test_size=0.2` and `random_state=42`.\n",
    "5) **Comment Your Code**: Get into the habit of including comments in your code. Comments should explain <u>why</u> decisions were made, while the code should be clean enough to read and understand <u>what</u> the program does. \n",
    "\n",
    "<span style=\"color:red\">Do not make changes to these training and test set DataFrames going forward. If you need to make changes, save them with a different name. CodeGrade will check them in their original form.</span>\n",
    "\n",
    "*You may add additional markdown and code blocks to this template as needed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2836b01f",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###\n",
    "# standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Do not change this option; This allows the CodeGrade auto grading to function correctly\n",
    "pd.set_option('display.max_columns', 20)\n",
    "np.set_printoptions(suppress=True)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the dataset\n",
    "student_data = pd.read_csv(\"student-mat.csv\")\n",
    "\n",
    "# Identify the target variable (G3)\n",
    "target = \"G3\"\n",
    "\n",
    "# Create feature matrix (X) and target vector (y)\n",
    "X = student_data.drop(columns=[target])\n",
    "y = student_data[target]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7396f0",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "Understanding your data is a crucial step before building any machine learning model. This exploration phase helps you identify patterns, detect anomalies, and uncover insights that will guide your modeling decisions. By thoroughly analyzing and visualizing the data, you can make informed choices on feature selection and preprocessing, ultimately improving your model's performance and reliability.\n",
    "\n",
    "This section won't be automatically graded, but you must include your analytical insight and screenshots of your plots in the Executive Summary report.\n",
    "\n",
    "In this section you should:\n",
    "1) **Study Attributes**: Thoroughly study the training set attributes and their characteristics.\n",
    "2) **Visualizations**: Use visualizations to effectively analyze and explore your data. Be ready to explain what the visualization shows and why it is important.  \n",
    "3) **Correlations**: Analyze correlations between your numeric attributes.\n",
    "\n",
    "*CodeGrade will only have matplotlib and seaborn libraries loaded. You can use other libraries (e.g., Plotly) or use software (e.g., Tableau) for your visualizations, but comment out any code that is not matplotlib or seaborn before submitting to CodeGrade including import statements.*\n",
    "\n",
    "You will include your analysis and at least three plots in your Executive Summary. Use either screenshots and paste them into your Executive Summary document or the `savefig()` method. Here's example code for saving a plot in different file formats:\n",
    "```\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your plotting code here\n",
    "plt.plot([1, 2, 3, 4], [10, 20, 25, 30])\n",
    "plt.xlabel('X-axis label')\n",
    "plt.ylabel('Y-axis label')\n",
    "plt.title('Sample Plot')\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig('my_plot.png')\n",
    "\n",
    "# Optionally, save in other formats\n",
    "plt.savefig('my_plot.pdf')\n",
    "plt.savefig('my_plot.jpg')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e604a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Numeric and categorical features\n",
    "numeric_features = student_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = student_data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "\n",
    "# Distribution of the target variable (G3)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(student_data[\"G3\"], kde=True, bins=20)\n",
    "plt.title(\"Distribution of Final Grade (G3)\")\n",
    "plt.xlabel(\"G3 Grade\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Correlation Heatmap for Numeric Features\n",
    "plt.figure(figsize=(12,10))\n",
    "corr = student_data[numeric_features].corr()\n",
    "sns.heatmap(corr, annot=False, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap of Numeric Features\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Top correlations with G3\n",
    "\n",
    "corr_with_G3 = corr[\"G3\"].sort_values(ascending=False)\n",
    "#print(\"Correlation of each numeric feature with G3:\")\n",
    "#display(corr_with_G3)\n",
    "\n",
    "\n",
    "# Boxplot of G3 by school\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(x=\"school\", y=\"G3\", data=student_data)\n",
    "plt.title(\"Final Grade (G3) by School\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 5. Countplot of categorical variables (example: internet)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.countplot(x=\"internet\", data=student_data)\n",
    "plt.title(\"Internet Access Distribution\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Relationship between studytime and G3\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.boxplot(x=\"studytime\", y=\"G3\", data=student_data)\n",
    "plt.title(\"Study Time vs Final Grade (G3)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Scatter: absences_G3 vs G3\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.scatterplot(x=\"absences_G3\", y=\"G3\", data=student_data)\n",
    "plt.title(\"Absences (G3 term) vs Final Grade\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520251cb",
   "metadata": {},
   "source": [
    "## Prepare the Data\n",
    "\n",
    "### Feature Selection\n",
    "\n",
    "Based on your data exploration, begin considering the features you want to include in your model. Limiting your data can be beneficial because it reduces complexity and can improve model performance by focusing on the most relevant features.\n",
    "\n",
    "Create lists below for the columns you want to use in your model based on your exploration above. These features will be used in the column transformer. The list names must match exactly.\n",
    "\n",
    "- **numeric_columns**: This is your continuous numerical data that MUST include `absences_G1`, `absences_G2`, `absences_G3`, `G1`, and `G2` for use in your custom transformer, in addition to any other numerical columns you want to select. Note: The fact that a column is labeled as an integer or float does not necessarily indicate that it contains continuous data.\n",
    "- **categorical_columns**: Include at least one categorical column.\n",
    "- **ordinal_columns**: Include at least one ordinal column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70809f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "# Numeric columns (must include absences_G1, absences_G2, absences_G3, G1, G2)\n",
    "numeric_columns = [\n",
    "    \"absences_G1\",\n",
    "    \"absences_G2\",\n",
    "    \"absences_G3\",\n",
    "    \"G1\",\n",
    "    \"G2\",\n",
    "    \"age\",\n",
    "    \"Medu\",\n",
    "    \"Fedu\",\n",
    "    \"traveltime\",\n",
    "    \"studytime\",\n",
    "    \"failures\",\n",
    "    \"famrel\",\n",
    "    \"freetime\",\n",
    "    \"goout\",\n",
    "    \"Dalc\",\n",
    "    \"Walc\",\n",
    "    \"health\"\n",
    "]\n",
    "\n",
    "# Categorical columns (at least one)\n",
    "categorical_columns = [\n",
    "    \"school\",\n",
    "    \"sex\",\n",
    "    \"address\",\n",
    "    \"famsize\",\n",
    "    \"Pstatus\",\n",
    "    \"Mjob\",\n",
    "    \"Fjob\",\n",
    "    \"reason\",\n",
    "    \"guardian\",\n",
    "    \"schoolsup\",\n",
    "    \"famsup\",\n",
    "    \"paid\",\n",
    "    \"activities\",\n",
    "    \"nursery\",\n",
    "    \"higher\",\n",
    "    \"internet\",\n",
    "    \"romantic\"\n",
    "]\n",
    "\n",
    "# Ordinal columns (at least one)\n",
    "ordinal_columns = [\n",
    "    \"class_quality\",   \n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4404e6d9",
   "metadata": {},
   "source": [
    "### Custom Transformer\n",
    "We want to create a new column that sums the three absences columns together as a new feature. Additionally, we want to  conditionally keep or drop the grades for the first and second terms based on the parameters passed.\n",
    "\n",
    "G3 is the final year grade and is highly correlated with G2 and G1, which are grades from the first two terms. Predicting G3 without using G2 and G1 is more challenging but also more valuable since you could make predictions earlier in the year. Therefore, later we will create separate models (one that includes the G1 and G2 columns and one that excludes them) to test this.\n",
    "\n",
    "#### Instructions for Submission\n",
    "\n",
    "Create a custom transformer that:\n",
    "\n",
    "- Inherits from BaseEstimator and TransformerMixin.\n",
    "- Implements the fit and transform methods.\n",
    "- Accepts a DataFrame as input. This differs from the California Housing Prices example, which used arrays. We will pass a DataFrame into the custom transformer to allow for easier testing with CodeGrade.\n",
    "- In the transform method:\n",
    "    - Create a new column called `absences_sum` that sums the `absences_G1`, `absences_G2`, and `absences_G3` columns, adds the new `absences_sum` column to the end of the DataFrame, then drops the original three absence columns.\n",
    "    - Drop the `G1` and `G2` columns if the parameter `drop_grades` is `True`. It will keep the columns if `drop_grades` is `False`.\n",
    "- Name the custom transformer class `FinalProjectTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fdd2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "\n",
    "class FinalProjectTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, drop_grades=False):\n",
    "        self.drop_grades = drop_grades\n",
    "        self.columns_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Store column names so we can rebuild the DataFrame during transform\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.columns_ = X.columns\n",
    "        else:\n",
    "            raise ValueError(\"Input to transformer must be a DataFrame\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Convert numpy array back into DataFrame\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            if self.columns_ is None:\n",
    "                raise ValueError(\"No column names stored — did you call fit first?\")\n",
    "            X = pd.DataFrame(X, columns=self.columns_)\n",
    "\n",
    "        X = X.copy()\n",
    "\n",
    "        # Create absences_sum column\n",
    "        X[\"absences_sum\"] = (\n",
    "            X[\"absences_G1\"] +\n",
    "            X[\"absences_G2\"] +\n",
    "            X[\"absences_G3\"]\n",
    "        )\n",
    "\n",
    "        # Drop original absence columns\n",
    "        X = X.drop(columns=[\"absences_G1\", \"absences_G2\", \"absences_G3\"])\n",
    "\n",
    "        # Optionally drop G1 and G2\n",
    "        if self.drop_grades:\n",
    "            X = X.drop(columns=[\"G1\", \"G2\"])\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526c8fb5",
   "metadata": {},
   "source": [
    "### Data Pipelines Instructions\n",
    "Creating data pipelines allows you to automate your data cleaning process, making it easy to apply the same transformations to new data. Follow the outline below to transform your dataset into two sets of transformed data: one with the G1/G2 columns and one without them.\n",
    "\n",
    "#### Instructions for Submission\n",
    "- Numeric Pipeline (you'll need to create two to handle the G1/G2 requirement)\n",
    "  - Impute missing values using SimpleImputer() (use [.set_output(transform=\"pandas\")](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_set_output.html) to output a DataFrame from your SimpleImputer into your custom transformer) \n",
    "  - Transform data using the custom transformer FinalProjectTransformer as appropriate for the task\n",
    "  - Standardize the data using StandardScalar()\n",
    "  - Use the following variable names:\n",
    "    - `numeric_pipeline_with_grades`\n",
    "    - `numeric_pipeline_without_grades`\n",
    "\n",
    "- Categorical Pipeline\n",
    "  - Impute missing values \n",
    "  - One-Hot Encode (OHE) categorical data \n",
    "  - Use the following variable name:\n",
    "    - `categorical_pipeline`\n",
    "\n",
    "- Ordinal Pipeline\n",
    "  - Impute missing values \n",
    "  - Ordinal encode the data\n",
    "  - Use the following variable name:\n",
    "    - `ordinal_pipeline`\n",
    "\n",
    "- Column Transformer (you'll need to create two to handle the two different numeric pipelines)\n",
    "  - pass in your previously created feature selection lists\n",
    "  - Combine the numeric, categorical, and ordinal pipelines\n",
    "  - Use the following variable names:\n",
    "    - `column_transformer_with_grades`\n",
    "    - `column_transformer_without_grades`\n",
    "    \n",
    "Once the full pipeline is set up, fit and transform `X_train`, saving the results as `X_train_transformed_with_grades` and `X_train_transformed_without_grades`. Confirm that the transformed data without grades has two fewer columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d33fc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#Feature Selection Lists (required by CodeGrade)\n",
    "\n",
    "numeric_columns = [\n",
    "    \"absences_G1\", \"absences_G2\", \"absences_G3\",\n",
    "    \"G1\", \"G2\",\n",
    "    \"age\", \"Medu\", \"Fedu\", \"traveltime\", \"studytime\",\n",
    "    \"failures\", \"famrel\", \"freetime\", \"goout\",\n",
    "    \"Dalc\", \"Walc\", \"health\"\n",
    "]\n",
    "\n",
    "categorical_columns = [\n",
    "    \"school\", \"sex\", \"address\", \"famsize\", \"Pstatus\", \"Mjob\", \"Fjob\",\n",
    "    \"reason\", \"guardian\", \"schoolsup\", \"famsup\", \"paid\", \"activities\",\n",
    "    \"nursery\", \"higher\", \"internet\", \"romantic\"\n",
    "]\n",
    "\n",
    "ordinal_columns = [\"Medu\"]   # valid ordinal column\n",
    "\n",
    "# Pipelines\n",
    "\n",
    "numeric_pipeline_with_grades = Pipeline([\n",
    "    (\"custom\", FinalProjectTransformer(drop_grades=False)),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "numeric_pipeline_without_grades = Pipeline([\n",
    "    (\"custom\", FinalProjectTransformer(drop_grades=True)),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "ordinal_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ordinal\", OrdinalEncoder())\n",
    "])\n",
    "\n",
    "# Column Transformers (must use numeric_columns etc.)\n",
    "\n",
    "column_transformer_with_grades = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline_with_grades, numeric_columns),\n",
    "    (\"cat\", categorical_pipeline, categorical_columns),\n",
    "    (\"ord\", ordinal_pipeline, ordinal_columns)\n",
    "])\n",
    "\n",
    "column_transformer_without_grades = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline_without_grades, numeric_columns),\n",
    "    (\"cat\", categorical_pipeline, categorical_columns),\n",
    "    (\"ord\", ordinal_pipeline, ordinal_columns)\n",
    "])\n",
    "\n",
    "# Fit/Transform\n",
    "X_train_transformed_with_grades = column_transformer_with_grades.fit_transform(X_train)\n",
    "X_train_transformed_without_grades = column_transformer_without_grades.fit_transform(X_train)\n",
    "\n",
    "X_train_transformed_with_grades.shape, X_train_transformed_without_grades.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bacc10",
   "metadata": {},
   "source": [
    "## Shortlist Promising Models\n",
    "In this section, you will fit and compare three regression models to your transformed data, both with and without the G1/G2 columns, using cross-validation. Follow the steps below, using the specified variable names.\n",
    "\n",
    "1) **Initialize Three Regression Models**\n",
    "- Linear Regression\n",
    "- Support Vector Machine (SVM) Regression\n",
    "- Lasso Regression\n",
    "\n",
    "2) **Compare Models with Cross-Validation**\n",
    "- Using the above models, perform cross-validation on each model using both sets of transformed data (with and without G1/G2 columns).\n",
    "\n",
    "### Instructions for Submission\n",
    "1) **Initialize the Models**: Instantiate a Linear Regression, SVM Regression, and Lasso Regression model.\n",
    "  - Use the specified variable names for the respective models:\n",
    "    - `lin_reg`\n",
    "    - `svm_reg`\n",
    "    - `lasso_reg`\n",
    "2) **Cross-Validation**: Using both sets of transformed data (with and without G1/G2 columns), perform 3-fold cross-validation for each model using RMSE as the metric.\n",
    "  - You will run cross-validation six times (e.g., cross-validation of the linear regression model with the G1/G2 data, cross-validation of the linear regression model without the G1/G2 data, etc.)\n",
    "  - Use the specified variable names to save each respective array of scores:\n",
    "    - `cv_scores_lin_reg_with_grades`\n",
    "    - `cv_scores_lin_reg_without_grades`\n",
    "    - `cv_scores_svm_with_grades`\n",
    "    - `cv_scores_svm_without_grades`\n",
    "    - `cv_scores_lasso_with_grades`\n",
    "    - `cv_scores_lasso_without_grades`\n",
    "  - Use the specified variable names to save the mean of each cross-validation array and print it to view your mean scores:\n",
    "    - `rmse_lin_reg_with_grades`\n",
    "    - `rmse_lin_reg_without_grades`\n",
    "    - `rmse_svm_with_grades`\n",
    "    - `rmse_svm_without_grades`\n",
    "    - `rmse_lasso_with_grades`\n",
    "    - `rmse_lasso_without_grades`\n",
    "\n",
    "*You are welcome to test and fit more regression models as long as the above three are included and named appropriately*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b6248",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "#  Initialize the models with required variable names\n",
    "lin_reg = LinearRegression()\n",
    "svm_reg = SVR(kernel=\"rbf\")\n",
    "lasso_reg = Lasso(alpha=0.1)\n",
    "\n",
    "#  Cross-validation (RMSE) WITH grades\n",
    "cv_scores_lin_reg_with_grades = cross_val_score(\n",
    "    lin_reg,\n",
    "    X_train_transformed_with_grades,\n",
    "    y_train,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "cv_scores_svm_with_grades = cross_val_score(\n",
    "    svm_reg,\n",
    "    X_train_transformed_with_grades,\n",
    "    y_train,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "cv_scores_lasso_with_grades = cross_val_score(\n",
    "    lasso_reg,\n",
    "    X_train_transformed_with_grades,\n",
    "    y_train,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "#  Cross-validation (RMSE) WITHOUT grades\n",
    "\n",
    "cv_scores_lin_reg_without_grades = cross_val_score(\n",
    "    lin_reg,\n",
    "    X_train_transformed_without_grades,\n",
    "    y_train,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "cv_scores_svm_without_grades = cross_val_score(\n",
    "    svm_reg,\n",
    "    X_train_transformed_without_grades,\n",
    "    y_train,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "cv_scores_lasso_without_grades = cross_val_score(\n",
    "    lasso_reg,\n",
    "    X_train_transformed_without_grades,\n",
    "    y_train,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "#  Compute mean RMSE values (convert signs)\n",
    "\n",
    "rmse_lin_reg_with_grades = -np.mean(cv_scores_lin_reg_with_grades)\n",
    "rmse_lin_reg_without_grades = -np.mean(cv_scores_lin_reg_without_grades)\n",
    "\n",
    "rmse_svm_with_grades = -np.mean(cv_scores_svm_with_grades)\n",
    "rmse_svm_without_grades = -np.mean(cv_scores_svm_without_grades)\n",
    "\n",
    "rmse_lasso_with_grades = -np.mean(cv_scores_lasso_with_grades)\n",
    "rmse_lasso_without_grades = -np.mean(cv_scores_lasso_without_grades)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8665ea9",
   "metadata": {},
   "source": [
    "## Fine-Tune the System\n",
    "In this section, you will use the Support Vector Machine (SVM) regression model and perform grid search to fine-tune its hyperparameters. Follow the steps below to set up the grid search, ensuring you use the specified variable names for automatic grading through CodeGrade.\n",
    "\n",
    "1) Set Up Grid Search for SVM Regression\n",
    "  - Define a parameter grid to search over. Review Scikit-learn's documentation for the available hyperparameters for this algorithm.\n",
    "  - Use GridSearchCV to find the best hyperparameters.\n",
    "  - Fit the grid search to both sets (with and without the G1/G2 columns) of the transformed training data.\n",
    "\n",
    "### Instructions for Submission\n",
    "\n",
    "1) **Define Parameter Grid**: Set up a parameter grid for the SVM regression model name `param_grid`.\n",
    "2) **Initialize Grid Search**: Initialize the `GridSearchCV` and call this `grid_search`.\n",
    "3) **Fit the Grid Search**: Fit the grid search to both sets (with and without the G1/G2 columns) of the transformed training data.\n",
    "4) **Save & Print Best Parameters**: Save the best parameters for each respective fit to `best_params_with_grades` and `best_params_without_grades`, and print them.\n",
    "5) **Print Best Score**: Use the `best_score_` attribute to view the mean cross-validated score for each respective best_estimator\n",
    "  \n",
    "<span style=\"color:red\">Codegrade has a runtime limit of 5 minutes. If your code takes longer than 5 minutes to run, the automatic grading will stop and mark the submission as having an error. Limiting the number of hyperparameters checked during your grid search may greatly reduce your code’s running time.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71a4dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Define a small parameter grid (fast for CodeGrade)\n",
    "\n",
    "param_grid = {\n",
    "    \"kernel\": [\"rbf\"],\n",
    "    \"C\": [1, 10],\n",
    "    \"gamma\": [\"scale\", \"auto\"]\n",
    "}\n",
    "\n",
    "#  Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=SVR(),\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "#  Fit the grid search WITH grades\n",
    "grid_search.fit(X_train_transformed_with_grades, y_train)\n",
    "\n",
    "best_params_with_grades = grid_search.best_params_\n",
    "best_score_with_grades = -grid_search.best_score_\n",
    "\n",
    "#print(\"Best Params WITH Grades:\", best_params_with_grades)\n",
    "#print(\"Best RMSE WITH Grades:\", best_score_with_grades)\n",
    "\n",
    "#  Fit the grid search WITHOUT grades\n",
    "grid_search.fit(X_train_transformed_without_grades, y_train)\n",
    "\n",
    "best_params_without_grades = grid_search.best_params_\n",
    "best_score_without_grades = -grid_search.best_score_\n",
    "\n",
    "#print(\"\\nBest Params WITHOUT Grades:\", best_params_without_grades)\n",
    "#print(\"Best RMSE WITHOUT Grades:\", best_score_without_grades)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07083c80",
   "metadata": {},
   "source": [
    "## Measure Performance on Test Set\n",
    "In this section, you will transform the test set using your full pipeline and measure the performance of your best model on the test set. Follow the steps below, using the specified variable names for automatic grading through CodeGrade.\n",
    "\n",
    "1) Based on all previous cross-validation results, pick your best model.\n",
    "2) Use the previously created column transformers to transform the test set, both with and without the G1/G2 columns.\n",
    "3) Using your best model, measure its performance on the test set to estimate the generalization error.\n",
    "  \n",
    "### Instructions for Submission\n",
    "1) **Fit Best Model**: If you haven't already, fit your best model to both sets of your transformed training data. \n",
    "2) **Transform the Test Set**: Use your column transformers to transform the test set (`X_test`), both with and without the G1/G2 columns. Name these transformed datasets `X_test_transformed_with_grades` and `X_test_transformed_without_grades`.\n",
    "3) **Evaluate Performance**: Measure the performance of your best-fitted models on the transformed test sets using Root Mean Squared Error (RMSE) and R-squared (R²) metrics. Save these variables as:\n",
    "  - `rmse_with_grades`\n",
    "  - `r2_with_grades`\n",
    "  - `rmse_without_grades`\n",
    "  - `r2_without_grades`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c8aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "#  Transform the X_test data (with and without grades)\n",
    "\n",
    "X_test_transformed_with_grades = column_transformer_with_grades.transform(X_test)\n",
    "X_test_transformed_without_grades = column_transformer_without_grades.transform(X_test)\n",
    "\n",
    "#  Fit the best model found by grid search\n",
    "\n",
    "# Best model WITH grades\n",
    "best_model_with_grades = grid_search.best_estimator_\n",
    "best_model_with_grades.fit(X_train_transformed_with_grades, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_with_grades = best_model_with_grades.predict(X_test_transformed_with_grades)\n",
    "\n",
    "rmse_with_grades = np.sqrt(mean_squared_error(y_test, y_pred_with_grades))\n",
    "r2_with_grades = r2_score(y_test, y_pred_with_grades)\n",
    "\n",
    "# Fit the best model WITHOUT grades\n",
    "best_model_without_grades = grid_search.best_estimator_\n",
    "best_model_without_grades.fit(X_train_transformed_without_grades, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_without_grades = best_model_without_grades.predict(X_test_transformed_without_grades)\n",
    "\n",
    "rmse_without_grades = np.sqrt(mean_squared_error(y_test, y_pred_without_grades))\n",
    "r2_without_grades = r2_score(y_test, y_pred_without_grades)\n",
    "\n",
    "\n",
    "#print(\"RMSE WITH GRADES:\", rmse_with_grades)\n",
    "#print(\"R2 WITH GRADES:\", r2_with_grades)\n",
    "#print(\"RMSE WITHOUT GRADES:\", rmse_without_grades)\n",
    "#print(\"R2 WITHOUT GRADES:\", r2_without_grades)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e9a2ed",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Codegrade has a runtime limit of 5 minutes.  If your code takes longer than 5 minutes to run, the automatic grading will stop and mark the submission as having an error.  Limiting the amount of hyperparameters checked during your grid search may greatly reduce your code’s running time.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bdc5a0",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "Once you complete all the steps above, you will:\n",
    "\n",
    "1) Upload your `final_project.ipynb` to the **Final Project Notebook Submission** link in Brightspace to check your work.\n",
    "2) After passing all unit tests in the automatic grading, finalize your **Executive Summary** document using the student instructions.\n",
    "3) Submit the **DTSC670_ExecutiveSummary_YourName** document through the **Final Project Executive Summary** submission link.\n",
    "\n",
    "<span style='color:red'>**BOTH** parts of this project must be completed and submitted to earn a grade.</span>\n",
    "\n",
    "<span style='color:red'>Submit your Executive Summary only **AFTER** submitting your final autograded notebook to CodeGrade and are satisfied with your score. Your CodeGrade submission score will be used to evaluate your overall project. Note that any CodeGrade submissions made after the Executive Summary has been submitted will not be considered.\n",
    "</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
